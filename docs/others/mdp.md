# マルコフ決定過程の基礎理論

ここでは強化学習の数学的基礎を与える **マルコフ決定過程** について概説します。もともと $Q$-学習の話とひとまとめにするつもりでしたが、理論の話をしていると結構長くなってしまったので分けました。

ここではマルコフ決定過程の数学的な性質、特に **ベルマンの最適性原理** について述べます。これはマルコフ性のおかげで、マルコフ決定過程ではある意味貪欲な戦略が最適になるということを主張する定理です。なお、ベルマンの最適性原理から存在が保証される最適な戦略を実際にどうやって計算するかといった、アルゴリズムに関する話は[$Q$-学習](./q_learning.md) の方を見てください。ある程度適切な条件下では $Q$-学習は、この問題に対する一つの効率的なアルゴリズムを与えます。また、今回は述べませんがベルマン方程式の線形性から $Q$-学習のような動的計画法だけでなく、線形計画法もマルコフ決定過程に対して有効なアプローチとなり、こちらは **オペレーションリサーチ** と呼ばれる分野で古くから調べられてきました。

ベルマンの最適性原理の証明に際して、高校の数学を超える範囲は縮小写像の不動点定理のみのはずで、この定理も度々大学入試問題で見られる定理なので、ご存知の方も多いかもしれません。なので恐らく高校生でも理解できるはずです。なお、念のため縮小写像の不動点定理については最後に[補足](#7)しておきますが、必要になり次第振り返るだけで十分だと思います。

マルコフ決定過程は上述した強化学習やオペレーションリサーチ以外にも **数理経済学** や **ゲーム理論** のような領域でも研究対象になっています。実際証明を覗いてみればゲーム理論などで頻繁に用いられる数学的手法が大活躍していることを見ることができるはずです。

1. [マルコフ決定過程](#1)
2. [方策と最適化問題の定式化](#2)
3. [ベルマン方程式](#3)
4. [ベルマンの最適性原理](#4)
5. [ベルマンの最適性原理の証明(概要)](#5)
6. [ベルマンの最適性原理の証明](#6)
7. [補遺：必要な数学の補足](#7)


## <a id="1">マルコフ決定過程の定義</a>
強化学習のもっとも標準的なモデルは **マルコフ決定過程(Markov Decision Process)** という数理モデルです。まず定義を見ておきましょう。

!!! note "定義(マルコフ決定過程)"

    有限集合 $S,A$ および関数 $T:S\times A\times S\to[0,1]$ および $R:S\times A\times S\to\mathbb{R}$ であって、任意の $s\in S,a\in A$ に対して、

    $$
    \sum_{s'\in S}T(s,a,s')=1
    $$

    を満たすような4つ組 $(S,A,T,R)$ を **マルコフ決定過程** という。また、$S$ を **状態空間(state space)** といい、$A$ を **行動空間(action space)** という。

定義がやや抽象的なのでマルコフ決定過程 $(S,A,T,R)$ の各要素の"気持ち"を書いておくと、

- $S$: モデルがとり得る状態全体の集合
- $A$: モデルがとれる行動全体の集合
- $T$: 状態が $s\in S$ のとき、行動 $a\in A$ をとった際に状態が $s'\in S$ に遷移する確率が $T(s,a,s')$
- $R$: 状態が $s\in S$ のとき、行動 $a\in A$ をとった際に状態が $s'\in S$ に遷移したときの報酬が $R(s,a,s')$


??? Tips "状態や行動が無限集合になる場合"

    ここでは数学的な煩雑さを避けるために最初から状態空間と行動空間に有限性を課しました。これを強調したい場合は **有限マルコフ決定過程(Finite Markov Decision Process)** と言ったりします。

    なお、発展的な話題を話しておくと、マルコフ決定過程は一般には $(S,\mathcal{S}),(A,\mathcal{A})$ が可測空間であれば定義されます。その際、確率関数 $T$ は **マルコフ核(Markov kernel)** $\kappa:S\times A\times\mathcal{S}\to[0,1]$ に置き換わります。ここで $\kappa$ は固定された $s\in S,a\in A$ に対して $\kappa(s,a,\cdot)$ が確率測度をなし、固定された $S'\in\mathcal{S}$ に対しては $\kappa(\cdot,\cdot,S')$ は可測関数であることが要請されます。報酬関数についてはそのまま可測性のみを課せば良いです。
    
    一般にこのような無限集合を扱うモデルは後述する$Q$-学習ような有限集合にのみ有効な手法は通用しませんが、**方策勾配法(policy gradient method)** の発見などによりこの種のモデルも現在では計算機で扱えるようになっており、より高度な強化学習においては用いられています。

## <a id="2">方策と最適化問題の定式化</a>
以降マルコフ決定過程 $(S,A,T,R)$ を固定して議論を進めます。ただの数理モデルを定義しただけでは何も面白くないですが、マルコフ決定過程モデルが与えられたとき、その上の **方策(policy)** を最適化するという問題が考えられるようになります。

!!! Note "定義(方策)"

    マルコフ決定過程 $(S,A,T,R)$ が与えられたとき、$\pi:S\times A\to[0,1]$ が **方策(policy)** であるとは、任意の $s\in S$ に対して $\sum_{a\in A}\pi(s,a)=1$ が成立することをいう。

方策 $\pi$ の "気持ち" は $s\in S$ にいるときにアクションとして $a\in A$ を選ぶ条件付き確率の値が $\pi(s,a)$ に対応するというものです。

さて、状態の初期値$s_0\in S$が固定されているとする。このとき、方策 $\pi$ が与えられたとき、確率変数の列$X_0,Y_0,X_1,Y_1,X_2,\ldots$ を以下の要領で帰納的に定めていくことができます。なお、$\{X_n\}$ は $S$ に値を取り、$\{Y_n\}$ は $A$ に値を取ります。

- まず $X_0$ は確率 $1$ で $s_0$ をとるものとする。
- $X_n$ が決まっているとき、$Y_n$ を分布 $\pi(X_n,\cdot)$ に沿って決める。つまり、任意の $s_0,s_1,\ldots,s_n\in S$ と $a_1,\ldots,a_{n-1},a_n\in A$ に対して、

$$
\Pr[Y_n=a_n|X_0=s_0,Y_0=a_0,\ldots,Y_{n-1}=a_{n-1},X_n=s_n]=\pi(s_n,a_n)
$$

を満たすように定める。

- $Y_n$ が決まっているとき、$X_{n+1}$ を分布 $T(X_n,Y_n,\cdot)$ に沿って決める。つまり、任意の $s_0,s_1,\ldots,s_n,s_{n+1}\in S$ と $a_1,\ldots,a_{n-1},a_n\in A$ に対して、

$$
\Pr[X_{n+1}=s_{n+1}|X_0=s_0,Y_0=a_0,\ldots,Y_{n-1}=a_{n-1},X_n=s_n,Y_n=a_n]=T(s_n,a_n,s_{n+1})
$$

を満たすように定める。

余談ですがこの状況では $\{X_n\}_{n\geqq0}$ が今の状況のみから次の遷移先が確率的に決定されるような確率過程である **マルコフ連鎖(Markov chain)** と呼ばれるものになります。

今、**割引率(discount ratio)** と呼ばれる値 $0\leq\gamma<1$ を予め定めておき、$\pi$ が方策全体を動くときに値

$$
\mathbb{E}\left[\sum_{n=0}^\infty\gamma^nR(X_n,Y_n,X_{n+1})\right]
$$

を $\pi$ について最大化するということがやりたいことになります。ここで確率変数 $X$ に対して $\mathbb{E}[X]$ で $X$ の期待値を表しています。また、ここでは $\gamma=0$ を許容していますが、その場合は $0^0=1$ と考えています。

??? Tips "期待値の収束性に関する注意"
    $R$ は有界なので、上式の期待値は収束することに注意しておきましょう。

なお、目的関数

$$
\mathbb{E}\left[\sum_{n=0}^\infty\gamma^nR(X_n,Y_n,X_{n+1})\right]
$$

の"気持ち"としては将来もらえる報酬は $\gamma^n$ だけ割り引いて勘定するということになります。これまでの話をまとめると、

- マルコフ決定過程では、**方策** を一つ決めるとマルコフ連鎖ができる。
- マルコフ連鎖から得られる報酬の期待値を方策を動かしたときに最大化する問題を考える。

ということになります。

??? "初期値が固定された場合の最適な方策の存在について"

    数学が強い方向けの補足ですが、この時点で方策全体はコンパクトであり、方策に対する目的関数の依存性が連続であることから直ちに初期値が固定された場合の最適方策の存在自体は分かります。以降もたびたび方策をパラメータに取る関数の最大値をとりますが、このような操作が許される理論的背景はここにあります。なお、ここで方策の定義域は有限集合なので、位相の入れ方は各点収束位相であろうが、適当なノルムから来る位相であろうが一致するのでさほど問題にしなくて良いです。

## <a id="3">ベルマン方程式</a>
さて、ここまでで述べてきた最適化問題は数学的には非常に素性が良いことが分かります。以下これを見ていきます。

この節でもマルコフ決定過程 $(S,A,T,R)$ および 割引率 $0\leq\gamma<1$ が固定されているものとしましょう。

まず、方策 $\pi$ と $s\in S$ に依存して決まる **状態価値関数(state-valued-function)** $V^\pi(s)$ を次式で定めます。

$$
V^\pi(s)=\mathbb{E}_\pi\left[\sum_{n=0}^\infty\gamma^nR(X_n,Y_n,X_{n+1})\mid X_0=s\right]
$$

ここで、$\{X_n\},\{Y_n\}$ は前節の議論で定めたような $X_0=s$ と初期値を指定したときに方策 $\pi$ に沿って定まる確率過程です。以降は $\pi,s$ への依存を明確にしたいときには上のような表記を用いることにします。


式変形を頑張っていくと、

$$
\begin{align*}
V^\pi(s)&=\mathbb{E}_\pi\left[\sum_{n=0}^\infty\gamma^nR(X_n,Y_n,X_{n+1})\mid X_0=s\right]\\
&=\mathbb{E}_\pi[R(s,Y_0,X_1)]+\gamma\mathbb{E}_\pi\left[\sum_{n=1}^\infty\gamma^{n-1}R(X_n,Y_n,X_{n+1})\mid X_0=s\right]\\
&=\sum_{a\in A,s'\in S}\pi(s,a)T(s,a,s')R(s,a,s')+\gamma\sum_{a\in A,s'\in S}\pi(s,a)T(s,a,s')\mathbb{E}_\pi\left[\sum_{n=0}^\infty\gamma^{n}R(X_{n+1},Y_{n+1},X_{n+2})\mid X_1=s'\right]\\
&=\sum_{s'\in S}\sum_{a\in A}\pi(s,a)T(s,a,s')\left(R(s,a,s')+\gamma V^\pi(s')\right)
\end{align*}
$$

となり、$\{V^\pi(s)\}_{s\in S}$ たちが満たすべき各$s\in S$ に対して定まる $|S|$ 個の方程式

$$
V^\pi(s)=\sum_{s'\in S}\sum_{a\in A}\pi(s,a)T(s,a,s')\left(R(s,a,s')+\gamma V^\pi(s')\right)
$$

が得られます。特にこれを **ベルマン方程式(Bellman equation)** と言います。ベルマン方程式の"気持ち"としては未来の予測報酬を再帰的に計算できるものと思ってもらって良いです。

## <a id="4">ベルマンの最適性原理</a>
マルコフ決定過程の素性の良さは以下の **ベルマンの最適性原理(Bellman principle of optimality)** で述べられます。

!!! Note "定理(ベルマンの最適性原理)"

    ある方策 $\pi^*$ が存在して、すべての $s\in S$ に対して、

    $$
    V^{\pi^*}(s)=\max_\pi V^\pi(s)
    $$

    が成立する。ここで $\max_\pi$ は方策全体に渡って最大化を行うという意味である。つまり、最適方策は初期値のとり方に依存しない。また、このような $\pi^*$ として各分布が決定的である、つまり、任意の $s\in S$ に対して、ある $a\in A$ が存在して、$\pi(s,a)=1$ となるものをとれる。

ベルマンの最適性原理で存在が保証されるような $\pi^*$ のことを **最適方策(optimal policy)** と言います。つまり、$\pi^*$ が最適方策とは任意の $s\in S$ に対して $V^{\pi^*}(s)=\max_\pi V^\pi(s)$ となることです。

以下ベルマンの最適性原理を証明していきます。証明に際して、縮小写像に対する不動点定理を用います。これについては最後に補遺という形で証明を付しておきますが、この定理さえ認めてもらえれば証明自体は読めると思います。

## <a id="5">ベルマンの最適性原理の証明(概要)</a>

証明の基本的なアイデアは方策そのものではなくて、$V$-関数に着目することです。もしベルマンの最適性原理が主張するような $\pi^*$ があったとして、

$$
V^{\pi^*}(s)=\max_\pi V^\pi(s)
$$

が成立します。さて、ベルマン方程式から

$$
V^{\pi^*}(s)=\sum_{s'\in S}\sum_{a\in A}\pi(s,a)T(s,a,s')\left(R(s,a,s')+\gamma V^\pi(s')\right)
$$

ですが、$\pi^*$ は決定的になるようにとれたことと、$V^{\pi^*}(s)=\max_\pi V^\pi(s)$ が成立することを合わせると、さらに変形できて

$$
V^{\pi^*}(s)=\max_{a\in A}\sum_{s'\in S}T(s,a,s')\left(R(s,a,s')+\gamma V^{\pi^*}(s')\right)
$$

が成立するはずです。注目すべきは両辺に $\pi^*$ が陽に現れておらず、$V^{\pi^*}$ の形でしか出現していないことです。そこで、まず $\pi^*$ を直接探すのではなく $\{V^{\pi^*}(s)\}_{s\in S}$ の値を探しにいきます。なお、上の方程式は **ベルマンの最適方程式(Bellman optimal equation)** といいます。つまり、関数 $V^*:S\to\mathbb{R}$ で任意の $s\in S$ について、

$$
V^*(s)=\max_{a\in A}\sum_{s'\in S}T(s,a,s')\left(R(s,a,s')+\gamma V^*(s')\right)
$$

を探します。ここで、[縮小写像に対する不動点定理](#7.3)を用います。不動点定理を用いると、一意な解 $V^*$ が存在することが分かるので、後は方策 $\pi$ で $V^\pi$ がベルマンの最適方程式を満たすようなものを見つけに行くと、これが $V^*$ と一致することから $\pi$ が最適方策であることが従います。

## <a id="6">ベルマンの最適性原理の証明</a>
概要の部分で述べた通り、ベルマンの最適性原理の証明はベルマンの最適方程式の解を求めることに帰着します。まずベルマン方程式の解が一意に存在することを示します。以下に示す一連の定理からベルマンの最適性原理が証明できていることが分かるでしょう。

実際に証明を行うにあたって、縮小写像の不動点定理が大活躍します。まずは不動点定理を適用する土台となる空間を定義しておきましょう。

!!! Note "定義"

    $S$ を有限集合とする。(この文書では状態空間を想定している。) $\mathbb{R}^S$ で $S$上の実数値関数全体の集合を表すものとする。このとき、各 $f\in\mathbb{R}^S$ に対して、

    $$
    \|f\|_\infty=\max_{s\in S}|f(s)|
    $$

    と定める。すぐに分かるように2点 $f,g\in\mathbb{R}^S$ の間の距離を $\|f-g\|_\infty=\max_{s\in S}|f(s)-g(s)|$ で定めることにより、 $(\mathbb{R}^S,\|\cdot\|_\infty)$ は[距離空間](#7.2)になる。以降断ることがない限り、$\mathbb{R}^S$ には $\|\cdot\|_\infty$ により距離構造を与える。なお、$\|\cdot\|_\infty$ による距離は **$\ell_\infty$-距離 ($\ell_\infty$-metric)** と呼ばれるものである。
    
    さらに $(\mathbb{R}^S,\|\cdot\|_\infty)$ は完備である。実際[コーシー列](#7.1) $\{f_n\}$ が与えられたとき、各 $s\in S$ に対して

    $$
    |f_n(s)-f_m(s)|\leq \|f_n-f_m\|_\infty\to 0\quad(n,m\to\infty)
    $$

    より $\{f_n(s)\}$ は $\mathbb{R}$ のコーシー列なので、実数の完備性から各 $s\in S$ に対して、 $f(s)=\lim_{n\to\infty}f_n(s)$ として $f\in\mathbb{R}^S$ を定められるが、このとき $\lim_{n\to\infty}f_n=f$ である。

!!! Note "定理 (ベルマンの最適方程式の解の存在と一意性)"
    マルコフ決定過程 $(S,A,T,R)$ と割引率 $0\leq\gamma<1$ が与えられているとする。このとき、ベルマンの最適方程式

    $$
    V(s)=\max_{a\in A}\sum_{s'\in S}T(s,a,s')\left(R(s,a,s')+\gamma V(s')\right)\quad(\forall\,s\in S)
    $$

    を満たす $V\in\mathbb{R}^S$ がただ一つ存在する。

??? "証明"

    $\mathcal{F}:\mathbb{R}^S\to\mathbb{R}^S$を、$f\in\mathbb{R}^S$ に対して

    $$
    (\mathcal{F} f)(s)=\max_{a\in A}\sum_{s'\in S}T(s,a,s')\left(R(s,a,s')+\gamma f(s')\right)
    $$

    とすることで定める。$V$ がベルマン最適方程式の解であることと $\mathcal{F}V=V$、すなわち $V$ が $\mathcal{F}$ の不動点であることは同値であることに注意する。ゆえに $\mathcal{F}$ が縮小写像であることを見れば証明が完了するが、これは任意の $f,g\in\mathbb{R}^S$ に対して、

    $$
    \begin{align*}
    &\|\mathcal{F}f-\mathcal{F}g\|_\infty\\
    =&\max_{s\in S}\left|\max_{a\in A}\left(\sum_{s'\in S}T(s,a,s')\left(R(s,a,s')+\gamma f(s')\right)\right)-\max_{a\in A}\left(\sum_{s'\in S}T(s,a,s')\left(R(s,a,s')+\gamma g(s')\right)\right)\right|\\
    \leqq&\max_{s\in S}\max_{a\in A}\left|\sum_{s'\in S}T(s,a,s')\left(R(s,a,s')+\gamma f(s')\right)-\sum_{s'\in S}T(s,a,s')\left(R(s,a,s')+\gamma g(s')\right)\right|\\
    =&\max_{s\in S}\max_{a\in A}\left|\gamma\sum_{s'\in S}T(s,a,s')(f(s')-g(s'))\right|\\
    \leqq&\max_{s\in S}\gamma |f(s')-g(s')|\\
    =&\gamma\|f-g\|_\infty
    \end{align*}
    $$

    となるので $0\leqq\gamma <1$ より縮小写像の不動点定理から従う。よって示された。

!!! Note "定理 (ベルマン最適方程式の解は方策で書ける)"

    マルコフ決定過程 $(S,A,T,R)$ と割引率 $0\leq\gamma<1$ が与えられているとする。このとき、ベルマンの最適方程式の唯一つの解 $V^*\in\mathbb{R}^S$ に対して、 $\pi_*:S\to A$ を $\pi_*(s)$ がベルマン最適方程式の右辺の最大値を与えるもの、つまり、

    $$
    \sum_{s'\in S}T(s,\pi_*(s),s')\left(R(s,\pi_*(s),s')+\gamma V^*(s')\right)=\max_{a\in A}\sum_{s'\in S}T(s,a,s')\left(R(s,a,s')+\gamma V^*(s')\right)
    $$

    がすべての $s\in S$ で成立するようにする。このとき、方策 $\pi^*$ を

    $$
    \pi^*(s,a)=\begin{cases}1 &(a=\pi_*(s))\\ 0 & (\mathrm{otherwise})\end{cases}
    $$

    として定めると、$V^{\pi^*}=V^*$ となる。

??? "証明"

    $\mathcal{G}:\mathbb{R}^S\to\mathbb{R}^S$ を各 $f\in\mathbb{R}^S$ に対して、

    $$
    (\mathcal{G}f)(s)=\sum_{s'\in S}\sum_{a\in A}T(s,a,s')\pi^*(s,a)(R(s,a,s')+\gamma f(s'))
    $$

    と定める。まず $V^{\pi^*}$ が $\mathcal{G}$ の不動点である、すなわち $\mathcal{G}V^{\pi^*}=V^{\pi^*}$ である。これはベルマン方程式そのものである。一方 $V^*$ も $\mathcal{G}$ の不動点である。実際、

    $$
    \begin{align*}
    (\mathcal{G}V^*)(s)&=\sum_{s'\in S}\sum_{a\in A}T(s,a,s')\pi^*(s,a)(R(s,a,s')+\gamma V^*(s'))\\
    &=\sum_{s'\in S}T(s,\pi_*(s),s')\left(R(s,\pi_*(s),s')+\gamma V^*(s')\right)\\
    &=\max_{a\in A}\sum_{s'\in S}T(s,a,s')\left(R(s,a,s')+\gamma V^*(s')\right)\\
    &=V^*(s)
    \end{align*}
    $$

    となるためである。また、 $\mathcal{G}$ は縮小写像である。これは、任意の $f,g\in\mathbb{R}^S$ に対して、

    $$
    \begin{align*}
    &\|\mathcal{G}f-\mathcal{G}g\|_\infty\\
    =&\max_{s\in S}\left|\sum_{s'\in S}\sum_{a\in A}T(s,a,s')\pi^*(s,a)(R(s,a,s')+\gamma f(s'))-\sum_{s'\in S}\sum_{a\in A}T(s,a,s')\pi^*(s,a)(R(s,a,s')+\gamma g(s'))\right|\\
    =&\max_{s\in S}\left|\gamma\sum_{s'\in S}\sum_{a\in A}T(s,a,s')\pi^*(s,a)(f(s')-g(s'))\right|\\
    &\leqq\gamma\|f-g\|_\infty
    \end{align*}
    $$

    より $0\leqq\gamma<1$ なので従う。以上から縮小写像の不動点の一意性より $V^{\pi^*}=V^*$ が分かる。

!!! Note "定理 (最適方策が存在する)"

    前の定理で定めた $\pi^*$ は最適方策になっている。つまり、任意の方策 $\pi$ と $s\in S$ に対して、

    $$
    V^{\pi^*}(s)\geqq V^\pi(s)
    $$

    が成立する。

??? "証明"

    ベルマン最適方程式の解の存在と一意性で用いた$\mathcal{F}:\mathbb{R}^S\to\mathbb{R}^S$を再び用いる。もう一度定義を書いておくと、$f\in\mathbb{R}^S$ に対して

    $$
    (\mathcal{F} f)(s)=\max_{a\in A}\sum_{s'\in S}T(s,a,s')\left(R(s,a,s')+\gamma f(s')\right)
    $$

    とすることで定める。これが縮小写像であることはベルマン最適方程式の解の存在と一意性のところで見たので、これまでの議論と不動点定理の証明から任意の $f\in\mathbb{R}^S$ に対して、すべての $s\in S$ について

    $$
    V^*(s)=\lim_{n\to\infty}(\mathcal{F}^n f)(s)
    $$

    が成立する。ここで、$\mathcal{F}^n$ とは $\mathcal{F}$ を $n$ 回適用した作用素、つまり $\mathcal{F}^1=\mathcal{F},\mathcal{F}^n=\mathcal{F}\circ\mathcal{F}^{n-1}(n\geqq2)$ として定まる写像のことである。

    今任意の方策 $\pi$ と $s\in S$ に対して、ベルマン方程式から

    $$
    \begin{align*}
    V^\pi(s)&=\sum_{s'\in S}\sum_{a\in A}T(s,a,s')\pi(s,a)(R(s,a,s')+\gamma V^\pi(s'))\\
    &\leqq\max_{a\in A}\sum_{s'\in S}T(s,a,s')\left(R(s,a,s')+\gamma V^\pi(s')\right)\\
    &=(\mathcal{F}V^\pi)(s)
    \end{align*}
    $$

    であり、さらにもし $f,g\in\mathbb{R}^S$ が任意の $s\in S$ に対して $f(s)\leqq g(s)$ を満たすならば

    $$
    \begin{align*}
    (\mathcal{F} f)(s)&=\max_{a\in A}\sum_{s'\in S}T(s,a,s')\left(R(s,a,s')+\gamma f(s')\right)\\
    &\leqq\max_{a\in A}\sum_{s'\in S}T(s,a,s')\left(R(s,a,s')+\gamma g(s')\right)\\
    &=(\mathcal{F} g)(s)
    \end{align*}
    $$

    となるから、以上より $\mathcal{F}^n V^\pi$ は各点で単調増加する、つまり任意の $s\in S$ に対して、

    $$
    V^\pi(s)\leqq(\mathcal{F}V^\pi)(s)\leqq(\mathcal{F}^2V^\pi)(s)\leqq\cdots\leqq (\mathcal{F}^nV^\pi)(s)\leqq\cdots
    $$

    なので、

    $$
    V^\pi(s)\leqq\lim_{n\to\infty}(\mathcal{F}^nV^\pi)(s)=V^*(s)=V^{\pi^*}(s)
    $$

    となって示したいことが得られた。

## <a id="7">補遺：数学の準備</a>

ベルマンの最適性原理の証明に際して縮小写像に対する不動点定理を用います。そのため、この節ではこれらについて解説しますが、この節は他の節とは独立しているので、ここから先に読んでも知っている人は読み飛ばしてもらっても構いません。

### <a id="7.1">実数の完備性</a>
すでに実数は馴染みのある集合かもしれませんが、正確に「実数とは何か」について触れておきましょう。理系の方は「中間値の定理」という定理について習ったと思いますが、これが典型的に実数を実数たらしめる **完備性(completeness)** と呼ばれる性質になります。完備性の正確な定義は同値な定義が様々知られていますが、今回は後々のことを考えてコーシー列の収束を用います。

!!! note "定義 (コーシー列)"

    数列 $\{a_n\}$ が **コーシー列** であるとは、

    $$
    \lim_{n,m\to\infty}|a_n-a_m|=0
    $$

    が成立する、すなわち任意の $\varepsilon>0$ に対して十分大きい自然数 $N$ が存在して、 $N\leqq n,m$ となる任意の自然数 $n,m$ に対して、

    $$
    |a_n-a_m|<\varepsilon
    $$

    となることをいう。

さて、以下の定義が実数の完備性です。これは実数に対して要請される公理の一つなので、今回は証明なしに公理として認めることにしますが、当然別の方法で実数の完備性を定義した場合にはその同値性を証明する必要があります。

!!! note "公理 (完備性)"

    任意のコーシー列は収束する。つまり、数列 $\{a_n\}$ がコーシー列であればある実数 $a\in\mathbb{R}$ が存在して、 $\lim_{n\to\infty}a_n=a$ となる。

??? 細かい補足

    実数はZFC公理系の上で完備全順序体であるような唯一つのモデルですが、厳密にはコーシー列の収束だけ実数の完備性を規定できません。これは全順序体にコーシー列の収束を要請したとしても超実数のような非アルキメデス的なモデルが存在するためです。そこでさらに「アルキメデスの公理」と呼ばれる公理を追加すると、今日知られる実数を完全に規定できます。

### <a id="7.2">距離空間</a>
!!! note "定義 (距離空間)"

    空でない集合 $X$ と関数 $d_X:X\times X\to[0,\infty)$ であって、以下の条件を満たす組 $(X,d_X)$ を **距離空間(metric space)** という。

    1. すべての $x\in X$ に対して、$d_X(x,x)=0$となる。
    2. すべての $x,y\in X$ に対して、$d_X(x,y)=d_X(y,x)$となる。
    3. すべての $x,y,z\in X$ に対して、$d_X(x,y)+d_X(y,z)\geq d_X(x,z)$となる。
    4. もし $x,y\in X$ が $d_X(x,y)=0$ を満たすなら、$x=y$となる。

!!! note "定義 (距離空間上の点の収束)"

    距離空間$(X,d_X)$の列 $x_1,x_2,\ldots,$が $x\in X$ に **収束する(converge)** とは、

    $$
    \lim_{n\to\infty}d_X(x_n,x)=0
    $$

    が成立することをいう。

!!! note "定義 (距離空間の完備性)"

    距離空間 $(X,d_X)$ の列 $x_1,x_2,\ldots,$ が **コーシー列(Cauchy sequence)** であるとは、
    
    $$
    \lim_{n,m\to\infty}d_X(x_n,x_m)=0
    $$

    となることをいう。また、 $(X,d_X)$ が **完備(complete)** であるとは、$X$ の任意のコーシー列が収束することをいう。

!!! note "定義 (縮小写像)"

    2つの距離空間 $(X,d_X),(Y,d_Y)$ の間の写像 $f:X\to Y$ が **縮小写像(contracting map)** であるとは、ある $0\leqq\gamma<1$ が存在して、任意の $x,y\in X$ に対して、

    $$
    d_Y(f(x),f(y))\leqq\gamma d_X(x,y)
    $$

    となることである。

### <a id="7.3">縮小写像の不動点定理</a>

!!! note "定理 (縮小写像の不動点定理)"

    $(X,d_X)$ を完備距離空間、$f:X\to X$ を縮小写像とする。このとき、$f$ はただ一つの不動点をもつ。すなわち、$f(x^*)=x^*$ を満たす $x^*\in X$ が唯一つ存在する。

    さらに任意の $x\in X$ に対して点列 $\{x_n\}$ を

    $$
    x_1=x^*,\quad x_{n+1}=f(x_n)\,(n\geqq 1)
    $$

    として定めると、$\lim_{n\to\infty}x_n=x$ となる。

??? "証明"

    $0\leqq\gamma<1$ を任意の $x,y\in X$ に対して、 $d_X(f(x),f(y))\leqq\gamma d_X(x,y)$ となるようにとる。$x\in X$ を任意にとり、定理の主張で定めた点列 $\{x_n\}$ を考える。この点列はコーシー列である。実際任意の $n\leqq m$ に対して、

    $$
    d_X(x_n,x_m)=\gamma d_X(x_{n-1},x_{m-1})=\cdots=\gamma^{n-1}d_X(x_1,x_{m-n+1})
    $$

    より $n,m\to\infty$ で

    $$
    \lim_{n,m\to\infty} d_X(x_n,x_m)=0
    $$

    となるためである。ゆえに完備性から $x^*=\lim_{n\to\infty}x_n$ をとると、

    $$
    \begin{align*}
    d_X(x^*,f(x^*))&\leqq\lim_{n\to\infty}d_X(x^*,x_n)+d_X(x_n,x_{n+1})+d_X(x_{n+1},f(x^*))\\
    &\leqq\lim_{n\to\infty}(1+\gamma)d_X(x^*,x_n)+d_X(x_n,x_{n+1})\\
    &=0
    \end{align*}
    $$

    となり、$f(x^*)=x^*$ を得る。よって $x^*$ は $f$ の不動点である。一方不動点 $y^*$ が他に存在したとすると、

    $$
    d_X(x^*,y^*)=d_X(f(x^*),f(y^*))\leqq\gamma d_X(x^*,y^*)
    $$

    より $\gamma<1$ なので $d_X(x^*,y^*)=0$ となって $x^*=y^*$ とならなければならないので示したいことが得られた。